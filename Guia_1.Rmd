---
title: "Ejercicios Regresión"
author: "Gloria"
date: '`r Sys.Date()`'
output: 
  
  html_document:
    keep_md: true
    toc: true
    toc_depth: 4
    code_folding: show
    toc_float: yes
    df_print: paged
    theme: flatly
    code_download: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,  echo = FALSE, warning= FALSE )
```
<br>
<br>

# Capítulo 1. Regresión Lineal Simple


<br>

## <span style="color:#18bc9c">Correlación</span>

<br>

### Ejercicio 1.1. \
<br>
En el archivo grasacerdos.xlsx se encuentran los datos del peso
vivo (PV, en Kg) y al espesor de grasa dorsal (EGD, en mm) de 30 lechones
elegidos al azar de una población de porcinos Duroc Jersey del Oeste de la
provincia de Buenos Aires. Se pide: \
<br>
(a) Dibujar el diagrama de dispersión e interpretarlo.\
<br>
(b) Calcular el coeficiente de correlación muestral y explíquelo.\
<br>
(c) ¿Hay suficiente evidencia para admitir asociación entre el peso y el espesor de grasa? $(\alpha = 0,05)$. Verifique los supuestos para decidir el indicador
que va a utilizar.\


```{r}

library(readxl)
library(ggplot2)

grasacerdos <- read_excel("~/AUSTRAL/RegresionAvanzada/Archivos de datos para TP-20250407/Datos para TPs-20230606/grasacerdos.xlsx")
print(head(grasacerdos,5))

grasacerdos[] <- lapply(grasacerdos, function(x) {
  if (is.character(x)) gsub(",", ".", x) else x
})


```
Cambiamos las "," por "." y visualizamos cuantos nulos hay  por columna. Convertimos las columnas de PV y EGD a numéricas. Pedimos el summary del dataframe. 

```{r}
print(str(grasacerdos))

print(sapply(grasacerdos, function(x) sum(is.na(x)))) #cuantos valores nulos por columna tiene el dataframe

library(dplyr)
grasacerdos <- grasacerdos|>transmute(
  PV= as.numeric(PV),
  EGD= as.numeric(EGD)
)
summary(grasacerdos)

```
<br>

#### (a) 


```{r}
library(lmtest)
attach(grasacerdos)

plot( PV,EGD, xlab= "PV, en Kg", ylab= "EGD, en mm", main= "Peso vivo vs Espesor de grasa dorsal", col= "#2c3e50", pch= 19)


```
```{r}
#Diagrama con ggplot
ggplot(data = grasacerdos, aes(x = PV, y = EGD)) +
  geom_point() +
  ggtitle("Peso vs  Espesor de grasa dorsal") +
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```
En los datos visualizados  no pareciera haber asociación entre las variables. 

#### (b)
<br>
En primer lugar analizo la normalidad de las variables mediante los gráficos de los histogramas, los qqplots y la prueba de Shapiro.
```{r}
par(mfrow = c(1, 2)) 
hist(PV, breaks = 10, main = "", xlab = "Peso VIVO", border = "#2c3e50") 
hist(EGD, breaks = 10, main = "", xlab = "Espesor de grasa dorsal", border = "#18bc9c")
```
```{r}
par(mfrow = c(1, 2)) 
qqnorm(PV, main = "Peso vivo", col = "#2c3e50") 
qqline(PV) 
qqnorm(EGD, main = "Espesor de grasa dorsal", col = "#18bc9c") 
qqline(EGD)
```
```{r}
par(mfrow = c(1, 1)) 

#Test de hipótesis para el análisis de normalidad 
shapiro.test(PV)
```


```{r}
shapiro.test(EGD)
```
Por el test de Shapiro Wilk no se puede rechazar la normalidad de los datos en ninguno de los dos casos. 
<br>
Análisis de la normalidad multivariada - Test de Henze Zirkler

```{r, echo=TRUE}
#Análisis de normalidad bivariada 
library(MVN)
attach(grasacerdos)
peso_egd=data.frame(PV,EGD)
#Usamos Test Henze-Zirkler para evaluar normalidad multivariada (bivariada en este caso)
respuesta_testHZ<-mvn(peso_egd , mvnTest = "hz")
print(respuesta_testHZ$multivariateNormality)
```
El test da por resultado que las variables son normales bivariadas.

La correlación entre ambas variables es:

```{r}
cor(PV, EGD, method= "pearson")
```
La correlación entre las variables es baja: Si el valor de r es cercano a 0, indica que no existe una tendencia
creciente o decreciente entre las variables estudiadas.


```{r}
cor.test(PV, EGD,method="pearson")
```
El test arroja que el valor p de la prueba de Pearson es 0.175. 


```{r}
library(corrplot)
M= cor(grasacerdos)
M
```
Si bien no es necesario aplicar el coeficiente de Spearman pues se satisfacen los supuestos, igualmente lo hago.

```{r}
cor.test(PV, EGD,method="spearman")
```

### Ejercicio 1.2.
<br>

Los datos del cuarteto de Anscombe se encuentran en el archivo
 anscombe.xlsx
 Se pide explorar los datos de la siguiente manera:\
 <br>
 (a) Graficar los cuatro pares de datos en un diagrama de dispersión cada
 uno.\
 <br>
 (b) Hallar los valores medios de las variables para cada para de datos.\
<br> (c) Hallar los valores de la dispersión para cada conjunto de datos.\
 <br>(d) Hallar el coeficiente muestral de correlación lineal en cada caso.\
 <br>(e) Observar, comentar y concluir.\
 <br>
 
#### (a)


```{r}
library(readxl)
library(gt)

anscombe_completos <- read_excel("~/AUSTRAL/RegresionAvanzada/Archivos de datos para TP-20250407/Datos para TPs-20230606/anscombe_completos.xlsx", 
    col_types = c("numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric"))

anscombe_completos[2,2]<-6.95



get_stats <- function(x, y) {
  # Create and store the linear model
  lin_mod <- lm(y ~ x)
  
  # Create data frame with statistics
  data.frame(
    media_x = mean(x),
    media_y = mean(y),
    var_x = var(x),
    var_y = var(y),
    correl = cor(x, y),
    rcuad = summary(lin_mod)$r.squared  # Fixed this line
  )
}


```


```{r}

resultados <- data.frame()

for (i in 1:4) {
  x <- anscombe_completos[[paste0("x", i)]]
  y <- anscombe_completos[[paste0("y", i)]]
  stats <- get_stats(x, y)
  stats$Grupo <- paste0("Grupo ", i)
  resultados <- rbind(resultados, stats)
  
}


```


```{r}
library(ggplot2)

# Crear un DataFrame combinando los datos de los cuatro grupos
anscombe_long <- data.frame(
  x = unlist(lapply(1:4, function(i) anscombe_completos[[paste0("x", i)]])),
  y = unlist(lapply(1:4, function(i) anscombe_completos[[paste0("y", i)]])),
  grupo = rep(paste0("Grupo ", 1:4), each = nrow(anscombe_completos))
)

if (!requireNamespace("ggthemes", quietly = TRUE)) {
  install.packages("ggthemes")
}

# Cargar ggthemes
library(ggthemes)

# Graficar los datos con ggplot2 y aplicar el tema Flatly
ggplot(anscombe_long, aes(x = x, y = y)) +
  geom_point(color="#2c3e50") +
  facet_wrap(~ grupo) +
  labs(title = "Gráficos de los cuatro grupos de Anscombe",
       x = "X",
       y = "Y") +
  theme_fivethirtyeight() +  # Tema Flatly de ggthemes
  theme(axis.title = element_text())
```

#### (b)

```{r}
resultados <- resultados |> select(Grupo, media_x, media_y, var_x, var_y, correl, rcuad) |> gt()

resultados
```  
## <span style="color:#18bc9c"> Modelo Lineal Simple</span>
<br>

### Ejercicio 1.3. \
<br>
El archivo peso_edad_colest.xlsx disponible en contiene regis
tros correspondientes a 25 individuos respecto de su peso, su edad y el nivel
 de colesterol total en sangre.
 Se pide: \
 <br>
 (a) Realizar el diagrama de dispersión de colesterol en función de la edad y
 de colesterol en función de peso. Le parece adecuado ajustar un modelo
 lineal para alguno de estos dos pares de variables?\
  <br>
 (b) Estime los coeficientes del modelo lineal para el colesterol en función de
 la edad.\
  <br>
 (c) Estime intervalos de confianza del 95% para los coeficientes del modelo
 y compare estos resultados con el test de Wald para los coeficientes. Le
 parece que hay asociación entre estos test y el test de la regresión?\
  <br>
 (d) A partir de esta recta estime los valores de E(Y) para x = 25 años y
 x =48años. Podría estimarse el valor de E(Y) para x = 80 años? \
  <br>
 (e) Testee la normalidad de los residuos y haga un gráfico para ver si son
 homocedásticos.\
  <br>

#### (a)

```{r}
library(readxl)
peso_edad_colest <- read_excel("~/AUSTRAL/RegresionAvanzada/Archivos de datos para TP-20250407/Datos para TPs-20230606/peso_edad_colest.xlsx")

library(ggplot2)
library(tidyverse)
library(patchwork)

p1<- ggplot(peso_edad_colest, aes(x = edad, y = colest)) +
  geom_point() +
  labs(title = "Colesterol vs Edad", x = "Edad", y = "Colesterol") +
  theme_minimal()
p2 <- ggplot(peso_edad_colest, aes(x = peso, y = colest)) +
  geom_point() +
  labs(title = "Colesterol vs Peso", x = "Peso", y = "Colesterol") +
  theme_minimal()

p1 / p2 

```
Viendo los gráficos de dispersión, pareciera  que el colesterol en función de la edad tiene una relación lineal más clara que el colesterol en función del peso. Por lo tanto, es más adecuado ajustar un modelo lineal para el colesterol en función de la edad.  

#### (b)

```{r}
modelo_edad <- lm(colest ~ edad, data =peso_edad_colest)

summary(modelo_edad)
```


```{r}
sd(peso_edad_colest$colest)*0.8811468/sd(peso_edad_colest$edad)
```


```{r}
cor(peso_edad_colest$colest, peso_edad_colest$edad, method = "pearson")
```

#### (c)

Test de Wald para los coeficientes del modelo:

```{r, echo=TRUE}
library(aod)
wald.test(b = coef(modelo_edad), Sigma = vcov(modelo_edad), Terms = 1:2) # chequeo B0 y B1
```
La prueba arroja que el valor p para la prueba de Wald es menor a 0.05, por lo que se rechaza la hipótesis nula de que los coeficientes son iguales a cero. Esto indica que hay evidencia para suponer una asociación significativa entre la edad y el colesterol total en sangre.\
<br>
Los intervalos de confianza a nivel 95% para los coeficientes del modelo son:

```{r, echo= TRUE}
confint(modelo_edad, level = 0.95)
```
Tanto los resultados del test de Wald como los intervalos de confianza coinciden que los coeficientes de la regresión son diferentes a cero. 

#### (d)


 
 
```{r}
# Estimación de E(Y) para x = 25 y x = 48

Estimacion_25= coef(modelo_edad)[1]+coef(modelo_edad)[2]*25
print (paste("La estimación para x=25 es", Estimacion_25) )
Estimacion_48= coef(modelo_edad)[1]+coef(modelo_edad)[2]*48
print (paste("La estimación para x= 48 es ", Estimacion_48))
```
```{r, echo=TRUE}
# Estimación de E(Y) para x = 80
 print(max(peso_edad_colest$edad))
 print(min(peso_edad_colest$edad))

```
Como los datos de edad que tenemos son toma los valores entre 20 y 60, no es posible realizar una estimación para X=80.

#### (e)  

Análisis de la normalidad de los residuos del modelo: \
<br>

```{r}
edad <- peso_edad_colest
edad$prediccion <- modelo_edad$fitted.values 
edad$residuos <- modelo_edad$residuals

ggplot(data = edad, aes(x = residuos)) + geom_histogram(aes(y = ..density..)) + 
  labs(title = "Histograma de los residuos") + theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5))
```
```{r}
qqnorm(modelo_edad$residuals) 
qqline(modelo_edad$residuals)
```
```{r}
shapiro.test(modelo_edad$residuals)
```
  
  
El p-valor de la prueba de Shapiro-Wilk es 0.5175, lo que indica que no se puede rechazar la hipótesis nula de normalidad de los residuos. \
<br>
Análisis de la homocedasticidad de los residuos del modelo: \

```{r}
ggplot(data = edad, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")

```
No se observa estructura en los residuos del modelo. \
<br>
Test de Breusch-Pagan para la homocedasticidad: \
```{r, echo=TRUE}
library(lmtest)
bptest(modelo_edad)
```
El p-value de la Prueba de Breusch-PAgan es 0.6908, por lo que no se rechaza la hipótesis nula de homocedasticidad. \

